{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04239fe-6f5a-4676-a1a7-4b01f808d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas -q\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# datasets\n",
    "url_listings = 'https://data.insideairbnb.com/united-states/co/denver/2024-09-28/data/listings.csv.gz'\n",
    "# url_calendar = 'https://data.insideairbnb.com/united-states/co/denver/2024-09-28/data/calendar.csv.gz'\n",
    "# url_reviews = 'https://data.insideairbnb.com/united-states/co/denver/2024-09-28/data/reviews.csv.gz'\n",
    "# url_neighbourhoods = 'https://data.insideairbnb.com/united-states/co/denver/2024-09-28/visualisations/neighbourhoods.csv'\n",
    "\n",
    "# load datasets into DataFrames\n",
    "listings = pd.read_csv(url_listings, compression='gzip')\n",
    "# calendar = pd.read_csv(url_calendar, compression='gzip')\n",
    "# reviews = pd.read_csv(url_reviews, compression='gzip')\n",
    "# neighbourhoods = pd.read_csv(url_neighbourhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69934da-7e21-4bc5-a845-01e3109fe848",
   "metadata": {},
   "source": [
    "September 28, 2024. Data for the 3rd quarter of the 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fa728d-e3d0-4e0c-af2a-bfb3d8f3bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property_type\n",
      "Entire home                           1644\n",
      "Entire rental unit                     966\n",
      "Entire condo                           503\n",
      "Entire guest suite                     429\n",
      "Private room in home                   425\n",
      "Entire townhouse                       398\n",
      "Entire guesthouse                      291\n",
      "Private room in townhouse               84\n",
      "Entire loft                             78\n",
      "Entire bungalow                         53\n",
      "Private room in rental unit             53\n",
      "Private room in bed and breakfast       28\n",
      "Private room in guest suite             20\n",
      "Room in aparthotel                      20\n",
      "Room in hotel                           19\n",
      "Private room in condo                   16\n",
      "Shared room in hostel                   15\n",
      "Shared room in home                     14\n",
      "Entire serviced apartment               13\n",
      "Private room in bungalow                12\n",
      "Tiny home                               11\n",
      "Entire cottage                          10\n",
      "Entire place                             9\n",
      "Camper/RV                                8\n",
      "Room in boutique hotel                   7\n",
      "Room in hostel                           6\n",
      "Private room in castle                   5\n",
      "Castle                                   4\n",
      "Private room in guesthouse               3\n",
      "Entire vacation home                     3\n",
      "Private room in hostel                   2\n",
      "Shared room in rental unit               2\n",
      "Entire villa                             2\n",
      "Private room in serviced apartment       1\n",
      "Private room                             1\n",
      "Private room in villa                    1\n",
      "Private room in cottage                  1\n",
      "Private room in loft                     1\n",
      "Private room in casa particular          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove features that are not needed (first impression)\n",
    "columns_to_remove = [\n",
    "    'id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'picture_url',\n",
    "    'host_id', 'host_url', 'host_name', 'host_since', 'host_location', \n",
    "    'host_about', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', \n",
    "    'host_listings_count', 'host_total_listings_count', 'host_verifications', \n",
    "    'bathrooms_text', 'calendar_updated', \n",
    "    'calendar_last_scraped', 'first_review', 'last_review', 'license', \n",
    "    'calculated_host_listings_count', 'name', 'description', \n",
    "    'neighborhood_overview', 'calculated_host_listings_count_entire_homes', \n",
    "    'calculated_host_listings_count_private_rooms', \n",
    "    'calculated_host_listings_count_shared_rooms', \n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', \n",
    "    'minimum_maximum_nights', 'maximum_maximum_nights', \n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'has_availability', \n",
    "    'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "    'number_of_reviews_ltm', 'number_of_reviews_l30d', 'reviews_per_month',\n",
    "    'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication', 'review_scores_location', \n",
    "    'review_scores_value', 'neighbourhood', 'neighbourhood_group_cleansed'\n",
    "    \n",
    "]\n",
    "\n",
    "data = listings.drop(columns=columns_to_remove)\n",
    "print(data['property_type'].value_counts())\n",
    "#print(data.columns)\n",
    "\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c09cc9-feaf-4dd4-bfee-da8fcdc99adf",
   "metadata": {},
   "source": [
    "Features in each dataset:\n",
    "\n",
    "Listings: ['id', 'name', 'host_id', 'host_name', 'neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'last_review', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365', 'number_of_reviews_ltm', 'license']\n",
    "\n",
    "Calendar: ['listing_id', 'date', 'available', 'price', 'adjusted_price', 'minimum_nights', 'maximum_nights']\n",
    "\n",
    "Reviews: ['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n",
    "\n",
    "Neighbourhoods: ['neighbourhood_group', 'neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220712d8-6aa4-4e32-84dd-10155575e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_time                            0\n",
      "neighbourhood_cleansed_Highland               0\n",
      "neighbourhood_cleansed_Northeast Park Hill    0\n",
      "neighbourhood_cleansed_North Park Hill        0\n",
      "neighbourhood_cleansed_North Capitol Hill     0\n",
      "neighbourhood_cleansed_Montclair              0\n",
      "neighbourhood_cleansed_Montbello              0\n",
      "neighbourhood_cleansed_Marston                0\n",
      "neighbourhood_cleansed_Mar Lee                0\n",
      "neighbourhood_cleansed_Lowry Field            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean and convert price\n",
    "data = data.dropna(subset=['price'])  # drop rows missing 'price'\n",
    "data['price'] = (\n",
    "    data['price']\n",
    "    .str.replace('$', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Convert % columns to numeric\n",
    "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "    # Remove trailing '%'\n",
    "    data[col] = data[col].str.replace('%', '', regex=False)\n",
    "    # Convert to numeric (non-numeric becomes NaN)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Binary columns: map 't'/'f' to 1/0\n",
    "binary_cols = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
    "for col in binary_cols:\n",
    "    data[col] = data[col].map({'t': 1, 'f': 0})\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# **MISSING-DATA STRATEGIES**\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# A) Handle review_scores_rating:\n",
    "#    - Create 'no_reviews' flag = 1 if missing, else 0\n",
    "#    - Fill missing 'review_scores_rating' with 0\n",
    "data['no_reviews'] = data['review_scores_rating'].isnull().astype(int)\n",
    "data['review_scores_rating'] = data['review_scores_rating'].fillna(0)\n",
    "\n",
    "# B) Handle host_response_time, host_response_rate, host_acceptance_rate:\n",
    "#    1) Replace \"N/A\" with np.nan (so we can detect real missingness)\n",
    "data['host_response_time'] = data['host_response_time'].replace('N/A', np.nan)\n",
    "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "    data[col] = data[col].replace('N/A', np.nan)\n",
    "\n",
    "#    2) Create a missingness flag for host_response_time\n",
    "data['host_response_time_missing'] = data['host_response_time'].isnull().astype(int)\n",
    "\n",
    "#    3) For numeric rates, fill missing with 0\n",
    "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "    data[col] = data[col].fillna(0)\n",
    "\n",
    "#    4) If you still want to keep host_response_time as ordinal,\n",
    "#       map known categories to integers, leaving NaN for missing\n",
    "response_time_order = {\n",
    "    \"within an hour\": 1,\n",
    "    \"within a few hours\": 2,\n",
    "    \"within a day\": 3,\n",
    "    \"a few days or more\": 4\n",
    "}\n",
    "data['host_response_time'] = data['host_response_time'].map(response_time_order)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# End of missing-data handling\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# threshold-based grouping\n",
    "threshold = 25\n",
    "counts = data['property_type'].value_counts()\n",
    "rare_property_types = counts[counts < threshold].index\n",
    "\n",
    "data['property_type'] = data['property_type'].apply(\n",
    "    lambda x: x if x not in rare_property_types else 'Other'\n",
    ")\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['property_type', 'room_type', 'neighbourhood_cleansed']\n",
    "data = pd.get_dummies(data, columns=categorical_cols, dummy_na=True)\n",
    "\n",
    "# Create a simple feature from amenities (count them)\n",
    "data['amenities_count'] = data['amenities'].apply(\n",
    "    lambda x: len(eval(x)) if pd.notnull(x) else 0\n",
    ")\n",
    "# ----------------------------\n",
    "# host_response_time\n",
    "# ----------------------------\n",
    "data['host_response_time'] = data['host_response_time'].fillna(5)\n",
    "\n",
    "# ----------------------------\n",
    "# host_is_superhost\n",
    "# ----------------------------\n",
    "data['host_is_superhost'] = data['host_is_superhost'].fillna(0)\n",
    "\n",
    "# ----------------------------\n",
    "# beds & bedrooms\n",
    "# ----------------------------\n",
    "data['beds'] = data['beds'].fillna(data['beds'].median())\n",
    "data['bedrooms'] = data['bedrooms'].fillna(data['bedrooms'].median())\n",
    "\n",
    "# Optional: verify no more missing\n",
    "print(data.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282e45be-4fc8-4ec5-98c5-79ef81d5c58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnull_perc = data.isnull().mean().sort_values(ascending=False)\\npd.set_option('display.max_rows', len(null_perc))\\nprint(null_perc)\\npd.reset_option('display.max_rows')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "null_perc = data.isnull().mean().sort_values(ascending=False)\n",
    "pd.set_option('display.max_rows', len(null_perc))\n",
    "print(null_perc)\n",
    "pd.reset_option('display.max_rows')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e4db16-9b4a-4fbc-b829-ebae1f80e47b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[\"Shampoo\", \"Paid washer \\\\u2013 In building\", \"Cleaning products\", \"Window AC unit\", \"Iron\", \"Toaster\", \"Wine glasses\", \"Long term stays allowed\", \"Keypad\", \"Smoke alarm\", \"Hangers\", \"Central heating\", \"Stove\", \"Coffee maker: drip coffee maker, french press\", \"Self check-in\", \"Ceiling fan\", \"Shower gel\", \"Fire extinguisher\", \"Outdoor dining area\", \"TV\", \"Bathtub\", \"Hair dryer\", \"Coffee\", \"Essentials\", \"Books and reading material\", \"Dedicated workspace\", \"Kitchen\", \"Microwave\", \"Cooking basics\", \"Ethernet connection\", \"Backyard\", \"Paid dryer \\\\u2013 In building\", \"Outdoor furniture\", \"Oven\", \"Pets allowed\", \"Dishes and silverware\", \"Freezer\", \"Hot water kettle\", \"Body soap\", \"Dining table\", \"Free street parking\", \"Bed linens\", \"Laundromat nearby\", \"Refrigerator\", \"Luggage dropoff allowed\", \"Private entrance\", \"Wifi\", \"Carbon monoxide alarm\", \"Hot water\", \"Patio or balcony\", \"Clothing storage\", \"Portable fans\", \"Baking sheet\"]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 13. TRAIN A PRICE PREDICTION MODEL\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     (RANDOM FOREST REGRESSOR)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m     27\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     28\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     29\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 14. PREDICT & EVALUATE\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    364\u001b[0m     X,\n\u001b[1;32m    365\u001b[0m     y,\n\u001b[1;32m    366\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    367\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[1;32m    369\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    370\u001b[0m )\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[1;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    928\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 929\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    436\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[\"Shampoo\", \"Paid washer \\\\u2013 In building\", \"Cleaning products\", \"Window AC unit\", \"Iron\", \"Toaster\", \"Wine glasses\", \"Long term stays allowed\", \"Keypad\", \"Smoke alarm\", \"Hangers\", \"Central heating\", \"Stove\", \"Coffee maker: drip coffee maker, french press\", \"Self check-in\", \"Ceiling fan\", \"Shower gel\", \"Fire extinguisher\", \"Outdoor dining area\", \"TV\", \"Bathtub\", \"Hair dryer\", \"Coffee\", \"Essentials\", \"Books and reading material\", \"Dedicated workspace\", \"Kitchen\", \"Microwave\", \"Cooking basics\", \"Ethernet connection\", \"Backyard\", \"Paid dryer \\\\u2013 In building\", \"Outdoor furniture\", \"Oven\", \"Pets allowed\", \"Dishes and silverware\", \"Freezer\", \"Hot water kettle\", \"Body soap\", \"Dining table\", \"Free street parking\", \"Bed linens\", \"Laundromat nearby\", \"Refrigerator\", \"Luggage dropoff allowed\", \"Private entrance\", \"Wifi\", \"Carbon monoxide alarm\", \"Hot water\", \"Patio or balcony\", \"Clothing storage\", \"Portable fans\", \"Baking sheet\"]'"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn requests -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# ----------------------------\n",
    "# 11. DEFINE FEATURES (X) AND TARGET (y)\n",
    "# ----------------------------\n",
    "# The target is 'price'\n",
    "y = data['price']\n",
    "X = data.drop(columns=['price'])\n",
    "\n",
    "# ----------------------------\n",
    "# 12. SPLIT INTO TRAIN & TEST SETS\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 13. TRAIN A PRICE PREDICTION MODEL\n",
    "#     (RANDOM FOREST REGRESSOR)\n",
    "# ----------------------------\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 14. PREDICT & EVALUATE\n",
    "# ----------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # sqrt of MSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Regressor Performance:\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  MAE:  {mae:.2f}\")\n",
    "print(f\"  R^2:  {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36504639-ea1a-4604-b7d0-4ea4fc9dff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor (Log-Transformed) Performance:\n",
      "  RMSE: 66.54\n",
      "  MAE:  41.01\n",
      "  R^2:  0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn requests -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "###############################################################################\n",
    "# 1) LOAD THE DATA\n",
    "###############################################################################\n",
    "url_listings = \"https://data.insideairbnb.com/united-states/co/denver/2024-09-28/data/listings.csv.gz\"\n",
    "listings = pd.read_csv(url_listings, compression='gzip')\n",
    "\n",
    "###############################################################################\n",
    "# 2) DROP COLUMNS THAT AREN'T NEEDED\n",
    "###############################################################################\n",
    "columns_to_remove = [\n",
    "    'id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'picture_url',\n",
    "    'host_id', 'host_url', 'host_name', 'host_since', 'host_location', \n",
    "    'host_about', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', \n",
    "    'host_listings_count', 'host_total_listings_count', 'host_verifications', \n",
    "    'bathrooms_text', 'calendar_updated', 'calendar_last_scraped', 'first_review', \n",
    "    'last_review', 'license', 'calculated_host_listings_count', 'name', \n",
    "    'description', 'neighborhood_overview', 'calculated_host_listings_count_entire_homes', \n",
    "    'calculated_host_listings_count_private_rooms', \n",
    "    'calculated_host_listings_count_shared_rooms', \n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', \n",
    "    'minimum_maximum_nights', 'maximum_maximum_nights', \n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'has_availability', \n",
    "    'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "    'number_of_reviews_ltm', 'number_of_reviews_l30d', 'reviews_per_month',\n",
    "    'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication', 'review_scores_location', \n",
    "    'review_scores_value', 'neighbourhood', 'neighbourhood_group_cleansed'\n",
    "]\n",
    "\n",
    "data = listings.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "###############################################################################\n",
    "# 3) DROP ROWS WITHOUT PRICE & CONVERT PRICE -> FLOAT\n",
    "###############################################################################\n",
    "data.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "data['price'] = (\n",
    "    data['price']\n",
    "    .str.replace('$', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 4) OPTIONAL: REMOVE EXTREME OUTLIERS (TOP 1% OF PRICE)\n",
    "###############################################################################\n",
    "upper_cap = data['price'].quantile(0.99)\n",
    "data = data[data['price'] < upper_cap]\n",
    "\n",
    "###############################################################################\n",
    "# 5) LOG-TRANSFORM THE TARGET (PRICE)\n",
    "###############################################################################\n",
    "# We'll replace 'price' in the DataFrame with its log-transform.\n",
    "# That way, we'll predict log_price, and then invert predictions later.\n",
    "data['log_price'] = np.log1p(data['price'])\n",
    "\n",
    "###############################################################################\n",
    "# 6) CONVERT PERCENTAGE COLUMNS TO NUMERIC\n",
    "###############################################################################\n",
    "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "    data[col] = data[col].str.replace('%', '', regex=False)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "###############################################################################\n",
    "# 7) CONVERT BINARY COLUMNS ('t'/'f' -> 1/0)\n",
    "###############################################################################\n",
    "binary_cols = ['host_is_superhost', 'host_has_profile_pic', \n",
    "               'host_identity_verified', 'instant_bookable']\n",
    "for col in binary_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].map({'t': 1, 'f': 0})\n",
    "\n",
    "###############################################################################\n",
    "# 8) HANDLE MISSING DATA\n",
    "###############################################################################\n",
    "\n",
    "# --- A) REVIEW SCORES ---\n",
    "data['no_reviews'] = data['review_scores_rating'].isnull().astype(int)\n",
    "data['review_scores_rating'] = data['review_scores_rating'].fillna(0)\n",
    "\n",
    "# --- B) HOST RESPONSE TIME ---\n",
    "data['host_response_time'] = data['host_response_time'].replace('N/A', np.nan)\n",
    "data['host_response_time_missing'] = data['host_response_time'].isnull().astype(int)\n",
    "\n",
    "# Fill numeric rates with 0 if missing\n",
    "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "    data[col] = data[col].replace('N/A', np.nan).fillna(0)\n",
    "\n",
    "# Map response time to numeric\n",
    "response_time_order = {\n",
    "    \"within an hour\": 1,\n",
    "    \"within a few hours\": 2,\n",
    "    \"within a day\": 3,\n",
    "    \"a few days or more\": 4\n",
    "}\n",
    "data['host_response_time'] = data['host_response_time'].map(response_time_order)\n",
    "data['host_response_time'] = data['host_response_time'].fillna(5)  # A separate 'unknown' code\n",
    "\n",
    "# --- C) FILL BEDS & BEDROOMS ---\n",
    "data['beds'] = data['beds'].fillna(data['beds'].median())\n",
    "data['bedrooms'] = data['bedrooms'].fillna(data['bedrooms'].median())\n",
    "\n",
    "# --- D) FILL BINARY HOST_IS_SUPERHOST IF MISSING ---\n",
    "if 'host_is_superhost' in data.columns:\n",
    "    data['host_is_superhost'] = data['host_is_superhost'].fillna(0)\n",
    "\n",
    "###############################################################################\n",
    "# 9) GROUP RARE PROPERTY TYPES\n",
    "###############################################################################\n",
    "if 'property_type' in data.columns:\n",
    "    threshold = 25\n",
    "    counts = data['property_type'].value_counts()\n",
    "    rare_property_types = counts[counts < threshold].index\n",
    "    data['property_type'] = data['property_type'].apply(\n",
    "        lambda x: x if x not in rare_property_types else 'Other'\n",
    "    )\n",
    "\n",
    "###############################################################################\n",
    "# 10) ONE-HOT ENCODE CATEGORICAL COLUMNS\n",
    "###############################################################################\n",
    "categorical_cols = []\n",
    "for col in ['property_type', 'room_type', 'neighbourhood_cleansed']:\n",
    "    if col in data.columns:\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_cols, dummy_na=True)\n",
    "\n",
    "###############################################################################\n",
    "# 11) CREATE AMENITIES COUNT FEATURE\n",
    "###############################################################################\n",
    "if 'amenities' in data.columns:\n",
    "    def count_amenities(amenities_str):\n",
    "        try:\n",
    "            # Use ast.literal_eval for safer evaluation of the JSON-like list\n",
    "            am_list = ast.literal_eval(amenities_str)\n",
    "            return len(am_list)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    data['amenities_count'] = data['amenities'].apply(\n",
    "        lambda x: count_amenities(x) if pd.notnull(x) else 0\n",
    "    )\n",
    "\n",
    "    data.drop(columns=['amenities'], inplace=True, errors='ignore')\n",
    "\n",
    "###############################################################################\n",
    "# 12) OPTIONAL: ADD LOCATION FEATURES IF AVAILABLE\n",
    "###############################################################################\n",
    "# If your dataset has 'latitude' and 'longitude', you can keep them.\n",
    "# E.g.:\n",
    "# data['lat'] = listings['latitude']\n",
    "# data['lon'] = listings['longitude']\n",
    "# # Or compute distance from downtown Denver using a haversine formula.\n",
    "\n",
    "# For now, we’ll just keep them if they exist:\n",
    "for col in ['latitude', 'longitude']:\n",
    "    if col in listings.columns:\n",
    "        data[col] = listings[col]\n",
    "\n",
    "###############################################################################\n",
    "# 13) DEFINE FEATURES (X) AND TARGET (y)\n",
    "###############################################################################\n",
    "# We'll predict \"log_price\" rather than raw \"price\".\n",
    "y = data['log_price']\n",
    "X = data.drop(columns=['price', 'log_price'], errors='ignore')\n",
    "\n",
    "# Restrict X to numeric columns only, to avoid conversion errors:\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "###############################################################################\n",
    "# 14) TRAIN-TEST SPLIT\n",
    "###############################################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 15) TRAIN A RANDOM FOREST REGRESSOR\n",
    "###############################################################################\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "###############################################################################\n",
    "# 16) PREDICT & EVALUATE (CONVERT LOG-PRICE BACK)\n",
    "###############################################################################\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)      # from log price back to real price\n",
    "y_test_exp = np.expm1(y_test)      # same for actual test data\n",
    "\n",
    "rmse = mean_squared_error(y_test_exp, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_exp, y_pred)\n",
    "r2 = r2_score(y_test_exp, y_pred)\n",
    "\n",
    "print(\"Random Forest Regressor (Log-Transformed) Performance:\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  MAE:  {mae:.2f}\")\n",
    "print(f\"  R^2:  {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abb846-fd45-4d14-a51c-83a681ee0c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
